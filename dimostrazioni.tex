%!TEX ROOT=formularioMatematica.tex
\section{Dimostrazioni}
Qui verranno inserite alcune dimostrazioni di teoremi o formule che vengono usate nel formulario.

\begin{proof}[\protect\hyperlink{teor:tfa-ext}{Teorema fondamentale dell'Algebra esteso}]
  Il polinomio $P(x)$ in virtù del teorema fondamentale dell'Algebra, ha in $\mathbb{C}$ almeno uno 
  zero. Indicato con $\alpha_1$ tale zero, risulta:
  \begin{equation*}
    P(x) = (x-\alpha_1)P_1(x)
  \end{equation*}
  essendo il quoziente $P_1(x)$ un polinomio, a coefficienti in $\mathbb{C}$, di grado $(n-1)$.\\
  Se $n-1>0$, allora, per il teorema fondamentale dell'Algebra, anche il polinomio $P_1(x)$ ha in
  $\mathbb{C}$ almeno uno zero. Indicando tale zero con $\alpha_2$ avremo:
  \begin{equation*}
    P_1(x)=(x-\alpha_2)P_2(x)
  \end{equation*}
  essendo il quoziente $P_2(x)$ un polinomio, a coefficienti in $\mathbb{C}$, di grado $(n-2)$.\\
  Risulta quindi:
  \begin{align*}
    P(x)&=\underbrace{(x-\alpha_1)(x-\alpha_2)\dotsm(x-\alpha_n)P_n(x)}_{n\text{ fattori}} = \\
        &(x-\alpha_1)(x-\alpha_2)\dotsm(x-\alpha_n)c
  \end{align*}
  essendo l'ultimo termine di grado zero pari ad una costante $c$.\\
  Poiché la costante $c$ è il coefficiente del termine di grado massimo $x^n$, ne segue che $c=a_n$
  da cui
  \begin{equation*}
    P(x) = a_n(x-\alpha_1)(x-\alpha_2)\dotsm(x-\alpha_n)
  \end{equation*}
\end{proof}

\begin{proof}
  [\protect\hyperlink{teor:limiteInfinitoFunzRaz}{Limite di una funzione razionale}]
  Se
  \begin{equation*}
    P(x)=a_nx^n+a_{n-1}x^{n-1}+\dotsb+a_0
  \end{equation*}
  è un polinomio di grado $n>0$, si può scrivere per $x\neq0$
  \begin{equation*}
    P(x) = x^n\left(a_n+\frac{a_{n-1}}{x}+\dotsb+\frac{a_0}{x^n}\right)
  \end{equation*}
  e quindi, poiché $\lim\limits_{x\to+\infty}\frac{1}{x^n}=0,\,\forall n\in\mathbb{N}_0$, risulta
  \begin{equation*}
    \lim\limits_{x\to\infty}x^n\left(a_n+\frac{a_{n-1}}{x}+\dotsb+\frac{a_0}{x^n}\right) = a_n
  \end{equation*}
  Si ha
  \begin{align*}
    \lim\limits_{x\to\infty}P(x)&=\lim\limits_{x\to\infty}=
    \lim\limits_{x\to\infty}\left(a_nx^n+a_{n-1}x^{n-1}+\dotsb+a_0\right)=\\
    &\lim\limits_{x\to\infty}\left(a_nx^n\right)
  \end{align*}
\end{proof}

\begin{proof}[\protect\hyperlink{teor:uniLim}{Unicità del limite}]
  Supponiamo per assurdo che la funzione $f$ per $x\to x_0$ ammetta due limiti distinti $l_1$ e 
  $l_2$, cioè che si abbia
  \begin{equation*}
    \lim\limits_{x\to x_0}f(x)=l_1\quad\lim\limits_{x\to x_0}f(x)=l_2
  \end{equation*}
  In base alla definizione di limite, preso comunque un numero $\varepsilon>0$, è possibile 
  determinare due numeri positivi $\delta_\varepsilon'$ e $\delta_\varepsilon''$ tali che, per ogni
  $x\in\mathscr{D}_f$, verificante la condizione
  \begin{align*}
    0&<\abs{x-x_0}<\delta_\varepsilon' \quad&\text{risulti}&\quad\abs{f(x)-l_1}<\varepsilon\\
    0&<\abs{x-x_0}<\delta_\varepsilon'' &\text{risulti}&\abs{f(x)-l_2}<\varepsilon\\
  \end{align*}
  Ora, sia $\delta_\varepsilon$ il minore tra i due numeri $\delta_\varepsilon',\delta_\varepsilon''$
  per
  \begin{equation*}
    0<\abs{x-x_0}<\delta_\varepsilon
  \end{equation*}
  risulteranno verificate entrambe le disequazioni precedenti e potremo scrivere
  \begin{equation*}
    \abs{l_1-l_2}=\abs{l_1-f(x)+f(x)-l_2}\leq\abs{f(x)-l_1}+\abs{f(x)-l_2}<\varepsilon+\varepsilon=
    \varepsilon2
  \end{equation*}
  Data l'arbitrarietà di $\varepsilon$, la condizione $\abs{l_1-l_2}<2\varepsilon$ implica che sia
  $\abs{l_1-l_2}=0$ cioè $l_1=l_2$.
\end{proof}

\begin{proof}[\protect\hyperlink{teor:confLim}{Teorema del confronto}]
  In base alla definizione di limite, preso comunque un numero $\varepsilon>0$, è possibile 
  determinare due numeri positivi $\delta_\varepsilon'$ e $\delta_\varepsilon''$ tali che, per ogni
  $x\in\mathscr{D}_f$, verificante la condizione
  \begin{alignat*}{2}
    0&<\abs{x-x_0}<\delta_\varepsilon' &\quad\text{risulti}\quad \abs{f(x)-l_1}<\varepsilon\\
    0&<\abs{x-x_0}<\delta_\varepsilon'' &\text{risulti} \abs{f(x)-l_2}<\varepsilon\\
  \end{alignat*}
  Ora, sia $\delta_\varepsilon$ il minore tra i due numeri $\delta_\varepsilon',\delta_\varepsilon''$
  per
  \begin{equation*}
    0<\abs{x-x_0}<\delta_\varepsilon
  \end{equation*}
  saranno verificate entrambe le disequazioni precedenti quindi
  \begin{equation*}
    l-\varepsilon<f(x)\leq g(x)\leq h(x)<l+\varepsilon
  \end{equation*}
  cioè
  \begin{equation*}
    \abs{g(x)-l}<\varepsilon
  \end{equation*}
\end{proof}

\begin{proof}[\protect\hyperlink{teor:segno}{Teorema della permanenza del segno}]
  Dimostriamo innanzitutto la prima parte del teorema.\\
  Sia $\varepsilon=\frac{\abs{l}}{2}$; per la definizione di limite è possibile determinare in 
  corrispondenza di tale $\varepsilon$, un numero $\delta_\varepsilon>0$ tale che se 
  $x\in\mathscr{D}_f$
  \begin{equation*}
    0<\abs{x-x_0}<\delta_\varepsilon\quad\text{implichi}\quad
    l-\frac{\abs{l}}{2}<f(x)<l+\frac{\abs{l}}{2}
  \end{equation*}
  Ne consegue la tesi non appena si osservi che
  \begin{equation*}
    \text{se}\, l<0\quad l+\frac{\abs{l}}{2}<0\quad\text{quindi}\quad f(x)<0
  \end{equation*}
  \begin{equation*}
    \text{se}\, l>0\quad l-\frac{\abs{l}}{2}>0\quad\text{quindi}\quad f(x)>0
  \end{equation*}
  Dimostriamo ora la seconda parte.\\
  Sia per esempio $f(x)>0$. Dalla definizione di limite è possibile determinare in 
  corrispondenza di tale $\varepsilon$, un numero $\delta_\varepsilon>0$ tale che se 
  $x\in\mathscr{D}_f$
  \begin{equation*}
    0<\abs{x-x_0}<\delta_\varepsilon\quad\text{implichi}\quad
    l-\varepsilon<f(x)<l+\varepsilon
  \end{equation*}
  Supponiamo ora per assurdo che sia $l<0$, scegliendo $\varepsilon=-\frac{l}{2}>0$; si avrebbe
  \begin{equation*}
    f(x)<\frac{l}{2}<0
  \end{equation*}
  contro l'ipotesi che sia $f(x)>0$. Sarà dunque $l\geq0$
\end{proof}

\begin{proof}[\protect\hyperlink{teor:sommaLimiti}{Limite di una somma}]
  Si ha intanto
  \begin{equation*}
    \abs{[f(x)+g(x)]}-(l_1+l_2)\leq\abs{f(x)-l_1}+\abs{g(x)-l)2}
  \end{equation*}
  e quindi, preso $\varepsilon>0$, se si vuol provare che il primo membro è più piccolo di 
  $\varepsilon$, basta verificare che ciascuno dei due addendi a secondo membro è più piccolo di
  $\frac{\varepsilon}{2}$.\\
  Ma questo è evidente per le definizioni stesse di limiti. Il primo addendo sarà minore di 
  $\frac{\varepsilon}{2}$ se
  \begin{equation*}
    0<\abs{x-x_0}<\delta_\varepsilon'
  \end{equation*}
  e il secondo se
  \begin{equation*}
    0<\abs{x-x_0}<\delta_\varepsilon''
  \end{equation*}
  ove i due numeri $\delta_\varepsilon'$ e $\delta_\varepsilon''$ possono essere diversi in quanto 
  si riferiscono a funzioni diverse.\\
  Detto allora $\delta_\varepsilon$ il minore dei due, scegliendo $x$ tale che
  \begin{equation*}
    0<\abs{x-x_0}<\delta_\varepsilon
  \end{equation*}
  si soddisfano entrambe le condizioni; quindi per valori di $x$ così scelti si avrà
  \begin{equation*}
    \abs{f(x)-l_1}<\frac{\varepsilon}{2}\quad\abs{g(x)-l_2}<\frac{\varepsilon}{2}
  \end{equation*}
  e di conseguenza
  \begin{equation*}
    \abs{[f(x)+g(x)]}-(l_1+l_2)<\varepsilon
  \end{equation*}
\end{proof}

\begin{proof}[\protect\hyperlink{teor:prodottoLimiti}{Limite di un prodotto}]
  Si ha
  \begin{align*}
    &\abs{f(x)\cdot g(x)-l_1\cdot l_2} = \\
    &\abs{f(x)\cdot g(x)+l_1\cdot g(x)-l_1\cdot g(x)-l_1\cdot l_2} =\\
    &\abs{g(x)\cdot(f(x)-l_1)+l_1\cdot(g(x)-l_2)}\leq\\
    &\abs{g(x)}\cdot\abs{f(x)-l_1}+\abs{l_1}\cdot
    \abs{g(x)-l_2}
  \end{align*}
  Fissato allora $\varepsilon'$ in modo che sia $0<\varepsilon'<1$, esiste in corrispondenza di esso 
  un numero positivo $\delta_{\varepsilon'}$ tale che, $\forall x\in I$ verificante la condizione
  $0<\abs{x-x_0}<\delta_{\varepsilon'}$, risulti
  \begin{equation*}
    \abs{f(x)-1}<\varepsilon'\quad\abs{g(x)-l_2}<\varepsilon'\quad\abs{g(x)}<\abs{l_2}+\varepsilon'
  \end{equation*}
  Si ricava quindi
  \begin{equation*}
    \abs{f(x)\cdot g(x)-l_1\cdot l_2}<(\abs{l_2}+\varepsilon')\varepsilon'+\abs{l_2}\varepsilon'<
    (\abs{l_2}+\abs{l_1}+1)\varepsilon'
  \end{equation*}
  poiché $\varepsilon'^2<\varepsilon'$, essendo $0<\varepsilon'<1$, se scegliamo $\varepsilon'$ non
  solo positivo e minore di $1$ ma anche minore di
  \begin{equation*}
    \frac{\varepsilon}{\abs{l_1}+\abs{l_2}+1}
  \end{equation*}
  si ottiene, per $x$ appartenente ad un opportuno intorno di $x_0$
  \begin{equation*}
    \abs{f(x)\cdot g(x)-l_1\cdot l_2}<\varepsilon
  \end{equation*}
\end{proof}

\begin{proof}[\protect\hyperlink{teor:rolle}{Teorema di Rolle}]
  \textbf{Ipotesi}:
  \begin{itemize}
    \item $f$ definita e continua in $[a,b]$
    \item $f$ derivabile in $]a,b[$
    \item $f(a)=f(b)$
  \end{itemize}
  \textbf{Tesi}:
  \begin{equation*}
    \exists\,c\in{]a,b[}\suchthat f'(c)=0
  \end{equation*}
  \divisor

  Per il teorema di Weistrass la $f$ ammette $\max$ e $\min$ assoluti.
  \begin{equation*}
    m = \min_{x\in{[a,b]}} f \quad M = \max_{x\in{[a,b]}}f
  \end{equation*}
  Si distinguono due casi
  \begin{enumerate}
    \item I punti di $\max$ e/o $\min$ coincidono con gli estremi
      \begin{equation*}
        m\leq f(x)\leq M
      \end{equation*}
      Visto che
      \begin{equation*}
        f(a) = f(b)
      \end{equation*}
      si ha che
      \begin{equation*}
        m = f(x)
      \end{equation*}
      Quindi
      \begin{equation*}
        f'(x) = 0\quad\forall x \in{[a,b]}
      \end{equation*}
    \item Almeno uno fra $\max$ e $\min$ sono interni all'intervallo ${[a,b]}$
      \begin{equation*}
        f(c) = M
      \end{equation*}
      Visto che in $c$, $\exists\,\max f$ e $f$ è derivabile,
      \begin{equation*}
        f'(c) = 0
      \end{equation*}
  \end{enumerate}
\end{proof}

\begin{proof}[\protect\hyperlink{teor:lagrange}{Teorema di Lagrange}]
  \textbf{Ipotesi}:
  \begin{itemize}
    \item $f$ definita e continua in $[a,b]$
    \item $f$ derivabile in $]a,b[$
  \end{itemize}
  \textbf{Tesi}:
  \begin{equation*}
    \exists\,x\in[a,b]\suchthat f'(x) = \frac{f(b)-f(a)}{b-a}
  \end{equation*}
  \divisor

  Sia $\phi(x) = f(x)-kx$ per una costante $k$ in modo che abbia le stesse caratteristiche di $f$,
  ovvero è continua ($f(x)$ è continua per ipotesi, $kx$ è continua perché polinomiale) e 
  derivablie ($\phi'(x) = f'(x)-k$).\\
  Per ricondursi a Rolle
  \begin{equation*}
    \phi(a) = \phi(b)
  \end{equation*}
  quindi
  \begin{align*}
    f(a)-ak &= f(b)-kb\\
    kb-ka &= f(b)-f(a)\\
    k(b-a) &= f(b)-f(a)\\
    k &= \frac{f(b)-f(a)}{b-a}
  \end{align*}
  Dato che il Teorema di Rolle ci dice
  \begin{equation*}
    \exists\,x_0\in[a,b]\suchthat f'(x)=0
  \end{equation*}
  si ha che
  \begin{equation*}
    \phi'(x) = f'(x)-\frac{f(b)-f(a)}{b-a} = 0
  \end{equation*}
  da cui si deriva che
  \begin{equation*}
    f'(x) = \frac{f(b)-f(a)}{b-a}
  \end{equation*}
\end{proof}

\begin{proof}
  [\protect\hyperlink{teor:lagrange:1}{Monotonia $\leftrightarrow$ Crescenza/Decrescenza}]
  \textbf{Ipotesi}:
  \begin{itemize}
    \item $f$ definita e continua in $[a,b]$
    \item $f$ derivabile in $]a,b[$
  \end{itemize}
  \textbf{Tesi}:
  \begin{itemize}
    \item Se $f'(x) > 0$, allora la funzione è crescente
    \item Se $f'(x) < 0$, allora la funzione è decrescente
  \end{itemize}
  \divisor

  Preso un intorno $I=[a,b]$ possiamo prendere un altro intorno $[x_1,x_2]\in I$. Per il teorema
  di Lagrange,
  \begin{equation*}
    \exists\,c\in]x_1,x_2[\suchthat \frac{f(x_2)-f(x_1)}{x_2-x_1}=f'(c)
  \end{equation*}
  Si distinguono i due casi
  \begin{description}
    \item[$f'(c)>0$] allora $x_2-x_1>0 \implies f(x_2)-f(x_1)>0 \implies\,\text{crescente}$ 
    \item[$f'(c)<0$] allora $x_2-x_1<0 \implies f(x_2)-f(x_1)<0\implies\,\text{decrescente}$
  \end{description}
\end{proof}

\begin{proof}
  [\protect\hyperlink{teor:lagrange:2}{Costanza}]
  \textbf{Ipotesi}: 
  \begin{itemize}
    \item $f$ definita e continua in $[a,b]$
    \item $f$ con derivata nulla in $]a,b[$
  \end{itemize}
  \textbf{Tesi}:
  \begin{equation*}
    f(x) = k
  \end{equation*}
  \divisor

  Si prenda un intorno $]x_1,x_2[\in I$, allora per il teorema di Lagrange
  \begin{equation*}
    \exists\,c\in]x_1,x_2[\suchthat \frac{f(x_2)-f(x_1)}{x_2-x_1}=f'(c)=0
  \end{equation*}
  per ipotesi. Quindi si ha che
  \begin{equation*}
    f(x_2) - f(x_1) = 0 \implies f(x_2) = f(x_1)
  \end{equation*}
\end{proof}

\begin{proof}
  [\protect\hyperlink{teor:der:Sec:1}{Massimi e minimi e flessi con derivata seconda}]
  \textbf{Ipotesi}:
  \begin{itemize}
    \item $f$ sia continua e derivabile almeno 3 volte
  \end{itemize}
  \textbf{Tesi}:
  \begin{equation*}
    f'(x_0)=f''(x_0)=\dotsb=f^{(n-1)}(x_0)=0\land f^{(n)}(x_0)\neq0
  \end{equation*}
  \begin{enumerate}
    \item Se $n$ pari è un massimo o un minimo a seconda del segno
    \item Se $n$ dispari è un flesso a tangente orizzontale
  \end{enumerate}
  \divisor

  Dimostriamo il punto 1). Se $f''(x)$ è continua in $x_0$ allora
  \begin{equation*}
    \lim\limits_{x\to x_0} f''(x) = f''(x_0)[>0]
  \end{equation*}
  Per il teorema della permanenza del segno
  \begin{equation*}
    \exists\,I(x_0)\suchthat f''(x)>0
  \end{equation*}
  Possiamo riscrivere
  \begin{equation*}
    f''(x) = \Dif[f'(x)]
  \end{equation*}
  Dato che sappiamo che $f''(x)$ è maggiore di zero, significa che $f'(x)$ è crescente nell'intorno
  per il primo Lemma del teorema di Lagrange. Se $f'(x_0) = 0$ come da ipotesi significa che questa
  funzione interseca l'asse delle $x$. Essendo crescente significa che il segno è
  \begin{center}
    \begin{tikzpicture}
      \drawSign{\x}{-1}{1}{0.25}{}%
      \end{tikzpicture}
  \end{center}
  e che quindi la funzione $f(x)$ di cui è derivata è prima decrescente e poi crescente in modo
  da avere una tangente orizzontale a $x_0$. Ciò significa che in $x_0$ c'è un minimo relativo. Per
  il massimo, si dimostra in modo analogo.\\ [\baselineskip]
  Dimostriamo il punto 2). Se $f''(x_0)=0\land f'''(x_0)>0$ si ha che 
  $\Dif[f'(x_0)]=0\land\Dif[f''(x_0)]>0$. Da ciò si deduce che in $x_0$, $f'(x)$ ha un punto di
  minimo relativo. Dato che $f'$ è sempre positivo, significa che $f$ è crescente e in $x_0$ ha
  una tangente orizzontale. Quindi il punto $x_0$ è un punto di flesso per $f$.
\end{proof}

\begin{proof}
  [\protect\hyperlink{teor:derSec:2}{Concavità con derivata seconda}]
  \textbf{Ipotesi}:
  \begin{itemize}
    \item $f$ sia continua e derivabile in $]a,b[$
    \item Esiste $f''(x)$
  \end{itemize}
  \textbf{Tesi}:
  \begin{description}
    \item[Se $f''(x_0)>0$] ha concavità verso l'alto
    \item[Se $f''(x_0)<0$] ha concavità verso il basso
    \item[Se $f''(x_0)=0$ e $f'''(x_0)\neq0$] in $x_0$ ha un flesso
  \end{description}
  \divisor

  Dimostriamo il primo punto, gli altri due si fanno in modo analogo. Avendo concavità verso l'alto
  significa che
  \begin{equation*}
    \exists\,I(x_0)\suchthat\,\forall x\in I(x_0) \Rightarrow f(x)-t(x)\geq0
  \end{equation*}
  Definiamo ora $\varphi(x) = f(x)-t(x)$, ovvero
  \begin{equation*}
    \varphi(x) = f(x)-t(x) = f(x)-f(x_0)-f'(x_0)(x-x_0)
  \end{equation*} 
  Andando a calcolare le prime derivate vediamo che
  \begin{equation*}
    \varphi'(x) = f'(x)-f'(x_0)\quad\varphi''(x)=f''(x)
  \end{equation*}
  Ponendo ora $\varphi(x_0) = 0$, vediamo che
  \begin{equation*}
    \varphi'(x_0)=0\quad\varphi''(x_0)=f''(x_0)>0
  \end{equation*}
  Dato che $\varphi'(x_0)=0$, significa che $x_0$ è un punto di minimo, di massimo o di flesso a
  tangente orizzontale per $\varphi$. Dato che la derivata seconda è positiva, significa che è
  un punto di minimo, perciò
  \begin{equation*}
    \exists\,I(x_0)\suchthat\varphi(x)\geq\varphi(x_0)\geq0 \Rightarrow f(x)-t(x)\geq 0
  \end{equation*}
\end{proof}

\begin{proof}
  [\protect\hyperlink{teor:media}{Teorema del valor medio}]
  \textbf{Ipotesi}:
  \begin{itemize}
    \item $f$ continua e definita in $[a,b]$
  \end{itemize}
  \textbf{Tesi}:
  \begin{itemize}
    \item $\exists\,c\in[a,b]\suchthat f(c)=\frac{1}{b-a}\int\limits_{a}^{b} f(x)\,\dif x$
  \end{itemize}
  \divisor

  Se $f$ è continua in $[a,b]$, per il teorema di Weistrass ammette $m=\min f$ e $M=\max f$.
  \begin{align*}
    m\leq &f(x) \leq M\\
    \int\limits_{a}^{b} m\,\dif x\leq
    &\int\limits_{a}^{b}f(x)\,\dif x\leq\int\limits_{a}^{b}M\,\dif x\\
    \left.mx\right|_a^b\leq &\int\limits_{a}^{b} f(x)\,\dif x\leq \left.Mx\right|_a^b\\
    m(b-a)\leq &\int\limits_{a}^{b} f(x)\,\dif x\leq M(b-a)\\
    m\leq &\frac{1}{b-a}\int\limits_{a}^{b} f(x)\,\dif x\leq M
  \end{align*}
  Ora per il teorema dei valori intermedi
  \begin{equation*}
    \exists\,c\in[a,b]\suchthat f(c)=\frac{1}{b-a}\int\limits_{a}^{b} f(x)\,\dif x
  \end{equation*}
\end{proof}

\begin{proof}
  [\protect\hyperlink{teor:tfci}{Teorema fondamentale del calcolo integrale}]
  \textbf{Ipotesi}:
  \begin{itemize}
    \item $f$ continua in $[a,b]$
  \end{itemize}
  \textbf{Tesi}:
  \begin{itemize}
    \item $F(x)$ derivabile per ogni $x\in[a,b]$
    \item $F'(x)=f(x)$ e $F(a)=0$
  \end{itemize}
  \divisor

  Se $F(x)$ è derivabile, significa che
  \begin{equation*}
    \exists\,\lim\limits_{h\to0} \frac{F(x+h)-F(x)}{h}
  \end{equation*}
  Abbiamo quindi che
  \begin{equation*}
    F(x) = \int\limits_{a}^{x} f(x)\,\dif x
  \end{equation*}
  e
  \begin{equation*}
    F(x+h) = \int\limits_{a}^{x+h} f(x)\,\dif x = \int\limits_{a}^{x} f(x)\,\dif x + 
    \int\limits_{x}^{x+h} f(x)\,\dif x
  \end{equation*}
  Il numeratore quindi diventa
  \begin{equation*}
    F(x+h)-F(x) = \cancel{\int\limits_{a}^{x} f(x)\,\dif x}+\int\limits_{x}^{x+h} f(x)\,\dif x
    -\cancel{\int\limits_{a}^{x} f(x)\,\dif x}
  \end{equation*}
  Possiamo quindi scrivere
  \begin{equation*}
    \frac{1}{h}\int\limits_{x}^{x+h} f(x)\,\dif x
  \end{equation*}
  Se è continua in $[a,b]$, deve esserlo anche in $[x,x+h]\subseteq[a,b]$.\\
  Per il teorema della media
  \begin{equation*}
    \exists c\in[x,x+h]\suchthat f(c)=\frac{1}{h}\int\limits_{x}^{x+h} f(x)\,\dif x
  \end{equation*}
  e quindi
  \begin{equation*}
    \frac{1}{h}\int\limits_{x}^{x+h} f(x)\,\dif x=\frac{1}{h}h f(c) = f(c)
  \end{equation*}
  Quindi infine possiamo scrivere
  \begin{equation*}
    \overbrace{\lim\limits_{h\to0} \frac{F(x+h)-F(x)}{h}}^{\mathclap{F'(x)}}=
    \lim\limits_{h\to0}f(x)=\overbrace{\lim\limits_{c\to x}f(c)}^{\mathclap{\text{Continua}}}=f(x)
  \end{equation*}
  E quindi
  \begin{equation*}
    F'(x) = f(x)
  \end{equation*}
\end{proof}

\begin{proof}
  [\protect\hyperlink{teor:deriv}{Teorema del criterio di derivabilità}]
  \textbf{Ipotesi:}
  \begin{itemize}
    \item $f(x)$ continua in $x_0$
    \item $f(x)$ derivabile in $U\setminus\{x_0\}$
  \end{itemize}
  \textbf{Tesi:}
  \begin{itemize}
    \item $f'(x_0)=\lim\limits_{x\to x_0} f'(x)$
  \end{itemize}
  \divisor

  Per definizione
  \begin{equation*}
    f'(x_0) = \lim\limits_{x\to x_0} \frac{f(x)-f(x_0)}{x-x_0}
  \end{equation*}
  Dato che $f$ è continua si può dire che
  \begin{equation*}
    \lim\limits_{x\to x_0} f(x) = f(x_0)
  \end{equation*}
  quindi, risolvendo la forma indeterminata $^0\!/_0$ usando l'Hôpital
  \begin{equation*}
    \lim\limits_{x\to x_0} \frac{f(x)-f(x_0)}{x-x_0}\Heq{\frac{0}{0}}\lim\limits_{x\to x_0} f'(x)
  \end{equation*}
  Se questo limite esiste ed è finito, si può scrivere l'equivalenza
  \begin{equation*}
    f'(x_0)\coloneqq\lim\limits_{x\to x_0} \frac{f(x)-f(x_0)}{x-x_0}=\lim\limits_{x\to x_0} f'(x)
  \end{equation*}
\end{proof}
